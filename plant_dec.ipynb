{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b5e0157",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d6ee5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Found 70295 images belonging to 37 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 1758/1758 [40:05<00:00,  1.37s/batch, loss=1.39] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 summary:\n",
      "  Train loss: 1.6387  Train acc: 0.5034\n",
      "  Val   loss: 0.6973  Val   acc: 0.7882\n",
      "  Saved best model (val_acc=0.7882) -> cnn_plant_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 1758/1758 [40:41<00:00,  1.39s/batch, loss=1.51] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 summary:\n",
      "  Train loss: 0.9736  Train acc: 0.6924\n",
      "  Val   loss: 0.5115  Val   acc: 0.8364\n",
      "  Saved best model (val_acc=0.8364) -> cnn_plant_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 1758/1758 [33:52<00:00,  1.16s/batch, loss=0.578]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 summary:\n",
      "  Train loss: 0.7642  Train acc: 0.7525\n",
      "  Val   loss: 0.2994  Val   acc: 0.9038\n",
      "  Saved best model (val_acc=0.9038) -> cnn_plant_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 1758/1758 [34:38<00:00,  1.18s/batch, loss=2.85] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 summary:\n",
      "  Train loss: 0.6382  Train acc: 0.7938\n",
      "  Val   loss: 0.2542  Val   acc: 0.9185\n",
      "  Saved best model (val_acc=0.9185) -> cnn_plant_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 1758/1758 [34:54<00:00,  1.19s/batch, loss=0.64] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 summary:\n",
      "  Train loss: 0.5499  Train acc: 0.8227\n",
      "  Val   loss: 0.1942  Val   acc: 0.9365\n",
      "  Saved best model (val_acc=0.9365) -> cnn_plant_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 1758/1758 [31:59<00:00,  1.09s/batch, loss=1.15] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 summary:\n",
      "  Train loss: 0.4892  Train acc: 0.8407\n",
      "  Val   loss: 0.1691  Val   acc: 0.9453\n",
      "  Saved best model (val_acc=0.9453) -> cnn_plant_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 1758/1758 [33:20<00:00,  1.14s/batch, loss=0.107] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 summary:\n",
      "  Train loss: 0.4417  Train acc: 0.8591\n",
      "  Val   loss: 0.1539  Val   acc: 0.9491\n",
      "  Saved best model (val_acc=0.9491) -> cnn_plant_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 1758/1758 [32:55<00:00,  1.12s/batch, loss=0.342] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 summary:\n",
      "  Train loss: 0.3963  Train acc: 0.8714\n",
      "  Val   loss: 0.1289  Val   acc: 0.9562\n",
      "  Saved best model (val_acc=0.9562) -> cnn_plant_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 1758/1758 [32:15<00:00,  1.10s/batch, loss=0.504] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 summary:\n",
      "  Train loss: 0.3630  Train acc: 0.8822\n",
      "  Val   loss: 0.1195  Val   acc: 0.9631\n",
      "  Saved best model (val_acc=0.9631) -> cnn_plant_classifier.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 1758/1758 [31:03<00:00,  1.06s/batch, loss=0.185] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10 summary:\n",
      "  Train loss: 0.3388  Train acc: 0.8898\n",
      "  Val   loss: 0.1087  Val   acc: 0.9637\n",
      "  Saved best model (val_acc=0.9637) -> cnn_plant_classifier.pth\n",
      "\n",
      "Loading best model and running final evaluation on validation set...\n",
      "Final Val loss: 0.1087    Final Val acc: 0.9637\n",
      "\n",
      "Classification report on Validation set:\n",
      "                                                    precision    recall  f1-score   support\n",
      "\n",
      "                                 Apple___Black_rot     0.9707    0.9954    0.9829       432\n",
      "                          Apple___Cedar_apple_rust     0.9476    0.9864    0.9666       733\n",
      "                                   Apple___healthy     0.9724    0.9628    0.9676       403\n",
      "                               Blueberry___healthy     0.9532    0.9802    0.9665       353\n",
      "          Cherry_(including_sour)___Powdery_mildew     0.9970    0.9883    0.9926       341\n",
      "                 Cherry_(including_sour)___healthy     0.9707    0.9785    0.9746       372\n",
      "Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot     0.9531    0.9215    0.9370       331\n",
      "                       Corn_(maize)___Common_rust_     0.9769    0.9794    0.9781       388\n",
      "               Corn_(maize)___Northern_Leaf_Blight     0.9236    0.9766    0.9494       384\n",
      "                            Corn_(maize)___healthy     0.9971    1.0000    0.9986       349\n",
      "                                 Grape___Black_rot     0.9502    0.9948    0.9720       384\n",
      "                      Grape___Esca_(Black_Measles)     0.9972    0.9624    0.9795       372\n",
      "        Grape___Leaf_blight_(Isariopsis_Leaf_Spot)     0.9972    0.9753    0.9861       364\n",
      "                                   Grape___healthy     0.9773    0.9942    0.9857       347\n",
      "          Orange___Haunglongbing_(Citrus_greening)     0.9948    0.9974    0.9961       386\n",
      "                            Peach___Bacterial_spot     0.9806    0.9671    0.9738       365\n",
      "                                   Peach___healthy     0.9857    0.9885    0.9871       349\n",
      "                     Pepper,_bell___Bacterial_spot     0.9783    0.9525    0.9652       379\n",
      "                            Pepper,_bell___healthy     0.9781    0.9299    0.9534       385\n",
      "                             Potato___Early_blight     0.9946    0.9973    0.9959       367\n",
      "                              Potato___Late_blight     0.9298    0.9416    0.9357       394\n",
      "                                  Potato___healthy     0.9745    0.9399    0.9569       366\n",
      "                               Raspberry___healthy     0.9673    0.9819    0.9745       331\n",
      "                                 Soybean___healthy     0.9603    0.9699    0.9651       399\n",
      "                           Squash___Powdery_mildew     0.9888    0.9944    0.9915       354\n",
      "                          Strawberry___Leaf_scorch     0.9854    0.9970    0.9912       338\n",
      "                              Strawberry___healthy     0.9925    0.9925    0.9925       398\n",
      "                           Tomato___Bacterial_spot     0.9421    0.9687    0.9552       319\n",
      "                             Tomato___Early_blight     0.8727    0.8797    0.8762       374\n",
      "                              Tomato___Late_blight     0.9587    0.7824    0.8616       386\n",
      "                                Tomato___Leaf_Mold     0.9867    0.9514    0.9688       391\n",
      "                       Tomato___Septoria_leaf_spot     0.9319    0.9474    0.9396       361\n",
      "     Tomato___Spider_mites Two-spotted_spider_mite     0.9553    0.8797    0.9160       316\n",
      "                              Tomato___Target_Spot     0.8223    0.9303    0.8730       373\n",
      "            Tomato___Tomato_Yellow_Leaf_Curl_Virus     0.9769    0.9820    0.9794       388\n",
      "                      Tomato___Tomato_mosaic_virus     0.9783    0.9810    0.9796       368\n",
      "                                  Tomato___healthy     0.9786    0.9809    0.9797       419\n",
      "\n",
      "                                          accuracy                         0.9637     14059\n",
      "                                         macro avg     0.9648    0.9629    0.9634     14059\n",
      "                                      weighted avg     0.9644    0.9637    0.9635     14059\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "DATA_DIR = r\"C:\\\\Users\\\\New User\\\\OneDrive\\\\Desktop\\\\plant_disease\\\\data\\\\New Plant Diseases Dataset(Augmented)\\\\New Plant Diseases Dataset(Augmented)\\\\train\"\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 64\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 1e-3\n",
    "VALID_SPLIT = 0.2\n",
    "SEED = 42\n",
    "MODEL_SAVE_PATH = \"cnn_plant_classifier.pth\"\n",
    "# ----------------------------\n",
    "\n",
    "# reproducibility\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# check data path\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    raise FileNotFoundError(f\"Data directory not found: {DATA_DIR}\\nPlease update DATA_DIR to the folder containing class subfolders.\")\n",
    "\n",
    "# transforms (train has light augmentation, test only normalization)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# load dataset\n",
    "full_dataset = datasets.ImageFolder(root=DATA_DIR, transform=train_transform)\n",
    "class_names = full_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"Found {len(full_dataset)} images belonging to {num_classes} classes.\")\n",
    "\n",
    "# split\n",
    "num_val = int(VALID_SPLIT * len(full_dataset))\n",
    "num_train = len(full_dataset) - num_val\n",
    "train_dataset, val_dataset = random_split(full_dataset, [num_train, num_val],\n",
    "                                         generator=torch.Generator().manual_seed(SEED))\n",
    "# set val dataset to use test_transform (override transform)\n",
    "val_dataset.dataset = datasets.ImageFolder(root=DATA_DIR, transform=test_transform)\n",
    "\n",
    "# DataLoader: set num_workers=0 for Windows / if user has issues, try >0 on Linux\n",
    "num_workers = 0  # change to 4 if on Linux and it works\n",
    "pin_memory = True if torch.cuda.is_available() else False\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=num_workers, pin_memory=pin_memory)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "# ---------- Model ----------\n",
    "class CNN_Classification(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN_Classification, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1), nn.BatchNorm2d(32), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 64x64\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 32x32\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 16x16\n",
    "        )\n",
    "        # adaptive pooling to make it robust to input size\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))  # -> 128 * 4 * 4\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 * 4 * 4, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = CNN_Classification(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "# optional scheduler:\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3,)\n",
    "\n",
    "# ---------- Helper functions ----------\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labels = []\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labs in dataloader:\n",
    "            imgs = imgs.to(device)\n",
    "            labs = labs.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labs)\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            _, p = torch.max(outputs, 1)\n",
    "            preds.extend(p.cpu().numpy())\n",
    "            labels.extend(labs.cpu().numpy())\n",
    "    model.train()\n",
    "    avg_loss = running_loss / len(dataloader.dataset)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return avg_loss, acc, labels, preds\n",
    "\n",
    "# ---------- Training loop ----------\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS}\", unit=\"batch\")\n",
    "    for imgs, labs in loop:\n",
    "        imgs = imgs.to(device)\n",
    "        labs = labs.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_corrects += torch.sum(preds == labs.data).item()\n",
    "\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = running_corrects / len(train_loader.dataset)\n",
    "\n",
    "    # validation\n",
    "    val_loss, val_acc, val_labels, val_preds = evaluate(model, val_loader, device)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"\\nEpoch {epoch} summary:\")\n",
    "    print(f\"  Train loss: {epoch_loss:.4f}  Train acc: {epoch_acc:.4f}\")\n",
    "    print(f\"  Val   loss: {val_loss:.4f}  Val   acc: {val_acc:.4f}\")\n",
    "\n",
    "    # save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'class_names': class_names\n",
    "        }, MODEL_SAVE_PATH)\n",
    "        print(f\"  Saved best model (val_acc={val_acc:.4f}) -> {MODEL_SAVE_PATH}\")\n",
    "\n",
    "# ---------- Final evaluation ----------\n",
    "print(\"\\nLoading best model and running final evaluation on validation set...\")\n",
    "checkpoint = torch.load(MODEL_SAVE_PATH, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "val_loss, val_acc, val_labels, val_preds = evaluate(model, val_loader, device)\n",
    "print(f\"Final Val loss: {val_loss:.4f}    Final Val acc: {val_acc:.4f}\\n\")\n",
    "\n",
    "# classification report\n",
    "print(\"Classification report on Validation set:\")\n",
    "print(classification_report(val_labels, val_preds, target_names=class_names, digits=4, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1657fb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Corn_(maize)___Common_rust_\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# ---------- Load and preprocess a single test image ----------\n",
    "test_image_path = r\"C:\\Users\\New User\\OneDrive\\Desktop\\plant_disease\\data\\test\\test\\CornCommonRust2.JPG\"\n",
    "\n",
    "img = Image.open(test_image_path).convert(\"RGB\")  # ensure RGB\n",
    "img = test_transform(img).unsqueeze(0).to(device)  # apply same transform as validation/test\n",
    "\n",
    "# ---------- Make prediction ----------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(img)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "\n",
    "predicted_class = class_names[predicted.item()]\n",
    "print(f\"Predicted class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa9e497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Potato___Early_blight\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# ---------- Load and preprocess a single test image ----------\n",
    "test_image_path = r\"C:\\Users\\New User\\OneDrive\\Desktop\\plant_disease\\data\\test\\test\\PotatoEarlyBlight1.JPG\"\n",
    "\n",
    "img = Image.open(test_image_path).convert(\"RGB\")  # ensure RGB\n",
    "img = test_transform(img).unsqueeze(0).to(device)  # apply same transform as validation/test\n",
    "\n",
    "# ---------- Make prediction ----------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(img)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "\n",
    "predicted_class = class_names[predicted.item()]\n",
    "print(f\"Predicted class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e29eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"cnn_plant_classifier.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44ed21ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'class_names': class_names\n",
    "}, \"cnn_plant_classifier.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
